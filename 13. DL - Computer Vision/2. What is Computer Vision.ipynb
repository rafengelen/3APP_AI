{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Computer Vision?\n",
    "\n",
    "We could easily spend a whole course on CV alone, so this lesson will only be a brief introduction to this exciting field of computer science. CV focuses on replicating parts of the complexity of the human vision system, and enabling computers to identify and process objects in images and videos in a simimar way that humans do.\n",
    "It's been around for more than 50 years, and it's a mature field of computer science in it's own right. But now, by linking CV to the power of AI, and especially deep learning, we can see a tremendous boost in performance, and exciting new possibilities start to arise. One could even say that linking CV to deep learning was the catalyst AI needed to revive from the previous winter of AI, and become a booming and interesting field once more.\n",
    "\n",
    "Out of scope for this course, but if you're interested in a deep dive on the specifics of Computer Vision as a field on it's own: https://www.youtube.com/@firstprinciplesofcomputerv3258\n",
    "\n",
    "In this lesson on CV, we'll explain the basics of CV, but link it do deep learning, because it's one of those areas in AI that's proven to be production-ready, already bringing lots of business value to products & services that we use every day. Below are some examples.\n",
    "\n",
    "\n",
    "<img src=\"./resources/cv.gif\"  style=\"height: 150px\"/>\n",
    "<img src=\"./resources/face.gif\" style=\"height: 150px\"/>\n",
    "<img src=\"./resources/ar.gif\"  style=\"height: 150px\"/>\n",
    "<img src=\"./resources/hc.gif\"  style=\"height: 150px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Big Picture \n",
    "\n",
    "\n",
    "Watch the following video (from 0:00 till 10:16) for a quick and brief explanation of the main concepts.\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/-4E2-0sxVUM?start=0&end=616\"><img src=\"resources/video1.png\" width=\"400\"></a>\n",
    "\n",
    "a) Can you declare the following terms, used in Computer Vision:\n",
    "\n",
    "- color marker tracking\n",
    "- patches\n",
    "- kernel\n",
    "- convolution\n",
    "\n",
    "b) Name three kernels or filters that are combined in face recognition.\n",
    "\n",
    "c) Today Computer Vision is everywhere. Name three examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers\n",
    "\n",
    "# a) \n",
    "# color marker tracking: \n",
    "# patches: \n",
    "# kernel: \n",
    "# convolution: \n",
    "\n",
    "# b) \n",
    "\n",
    "# c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How do we recognize images?\n",
    "\n",
    "Let's first have a look at how we recognize images. Take a look at this picture. What can you see?\n",
    "\n",
    "<img src=\"./resources/face.png\"  style=\"height: 250px\"/>\n",
    "\n",
    "Is it a man with a right face? Or is it a man who is looking at you directly? If your attention is at the nose or the right contour, you’ll probably say the former. If you see the ear or the left contour, you’ll say the latter.\n",
    "\n",
    "The contours and edges of an image affect our perception. You might not have noticed, but our brain captures the patterns in figures to classify an object. And the kick of Computer Vision lies here. Our machine will be trained to classify images by detecting patterns like humans do. For example, in the case of *the cats and dogs* problem, the patterns will be like the shape of ears, eyes, colors and hairs and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. So what is a convolution?\n",
    "\n",
    "Let’s try to understand the concept of convolution with a simple 1-dimensional case first. Suppose our image is a 1D array with the numbers like below. We want to detect the point that the value changes from 0 to 1. Let's use a very simple filter with [-1, 1].\n",
    "\n",
    "<img src=\"./resources/filter1.png\"  style=\"height: 250px\"/>\n",
    "\n",
    "Passing the *filter* (or *kernel*) from left to right, each time we get the convolution value. So as you can see, we can capture the wanted pattern in the outcome. Then let’s try a 2-dimensional case.\n",
    "\n",
    "<img src=\"./resources/filter2.png\" style=\"height: 300px\"/>\n",
    "\n",
    "By definition, a convolution is a mathematical operation between an *input image* and a *filter* to produce an outcome or *feature map*. With this *feature map*, we detect a particular feature from the input image.\n",
    "\n",
    "<img src=\"./resources/realworld.png\"  style=\"height: 200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convolution - Exercise\n",
    "\n",
    "Can you compute these convolutions yourself? Calculate the feature map for each of the filters.\n",
    "\n",
    "#### Input image\n",
    "\n",
    "$$\\begin{bmatrix} 0&10&20&20&0 \\\\ 20&70&90&60&90 \\\\ 10&80&30&20&30 \\\\ 0&70&30&0&10 \\\\ 0&60&40&20&0 \\end{bmatrix}$$\n",
    "\n",
    "#### Filter 1\n",
    "\n",
    "$$\\begin{bmatrix} 1&0&-1 \\\\ 1&0&-1 \\\\ 1&0&-1 \\end{bmatrix}$$\n",
    "\n",
    "#### Filter 2\n",
    "\n",
    "$$\\begin{bmatrix} 1&1&1 \\\\ 0&0&0 \\\\ -1&-1&-1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "\n",
    "# Feature map for filter 1:\n",
    "#  |  |\n",
    "#---------\n",
    "#  |  |\n",
    "#---------\n",
    "#  |  |\n",
    "\n",
    "# Feature map for filter 2:\n",
    "#  |  |\n",
    "#---------\n",
    "#  |  |\n",
    "#---------\n",
    "#  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open this Excel document\n",
    "\n",
    "<a href=\"resources/Convolution.xlsx\">Convolution.xlsx</a>\n",
    "\n",
    "and input the values you calculated. Can you see in the resulting feature maps what these filters are doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "# Filter 1 detects ...\n",
    "# Filter 2 detects ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quickdraw\n",
    "\n",
    "After all the hard work in this notebook, let's play a little game. Quick, Draw! is an online game developed by Google that challenges players to draw a picture of an object or idea and then uses a neural network to guess what the drawings represent. The AI learns from each drawing, increasing its ability to guess correctly in the future.\n",
    "\n",
    "<img src=\"./resources/quick.png\"  style=\"height: 200px\"/>\n",
    "\n",
    "### Gameplay\n",
    "\n",
    "The player starts with an object to draw (for example it may say \"Draw a chair in under 20 seconds\"). Then the player has twenty seconds to draw that object. Based on what they draw, the AI guesses what they are drawing. When the drawing is close enough to the item they were given to draw, it will say something like \"I know, it's a chair!\" and the player will be moved on to the next round. There are six rounds in a game of Quick, Draw! and at the end the game shows what other people have drawn in the categories the player didn't draw successfully.\n",
    "\n",
    "Clear? Try it yourself: <a href=\"https://quickdraw.withgoogle.com/\">Quick, Draw!</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical CV Tasks\n",
    "\n",
    "Below you can see an overview of common CV problem tasks, where deep learning plays a pivotal role on conquering the objectives. For this introduction lesson, we'll focus on the simplest task, the one that started it all, the image classification task: determining what is in the picture...\n",
    "\n",
    "<img src=\"./resources/CV_tasks.png\"  style=\"height: 250px\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
