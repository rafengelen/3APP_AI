{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Convolutional Neural Networks\n",
    "\n",
    "We already know that a neural network is a type of machine learning which models itself after the human brain. This creates an Artificial Neural Network that via an algorithm allows the computer to learn by incorporating new data. We will now study a Convolutional Neural Network (CNN), a type of Artificial Neural Network - used in image recognition and processing - that was specifically designed to process pixel data and to detect patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what is a Convolutional Neural Network?\n",
    "\n",
    "As you can see in the image below, the process of building a Convolutional Neural Network for the classification of images always involves three major steps (by the way steps 1 and 2 can be repeated several times).\n",
    "\n",
    "- Step 1 : Convolution\n",
    "- Step 2 : Pooling\n",
    "- Step 3 : Flattening & Full connection\n",
    "\n",
    "<img src=\"./resources/cnn.jpeg\"  style=\"height: 270px\"/>\n",
    "\n",
    "In this Notebook we will be going through each of the above operations in detail.\n",
    "\n",
    "## Step 1. Convolution\n",
    "\n",
    "We already know what convolution filters are and what a Neural Network is. These two techniques are combined to construct the first layers of the CNN. The video below (from 0:09 till 8:01) will explain the general concept. After that we will explain the technique in more detail.\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/YRhxdVk_sIs?start=9&end=481\"><img src=\"resources/video2.png\" width=\"400\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What have we learned?\n",
    "\n",
    "- CNNs have hidden layers called __convolutional layers__, and these layers are what makes a CNN, well... a CNN!\n",
    "\n",
    "\n",
    "- Just like any other layer, a convolutional layer receives input, transforms the input in some way, and then outputs the transformed input to the next layer. The inputs to convolutional layers are called input channels, and the outputs are called output channels. The transformation that occurs is called a __convolution operation__.\n",
    "\n",
    "\n",
    "- With each convolutional layer, we need to specify the number of filters the layer should have. These filters are actually what detect the patterns. The __deeper__ the network goes, the __more sophisticated__ the filters become. In later layers, rather than edges and simple shapes (first layers), our filters may be able to detect specific objects like eyes, ears or hair. In deeper layers, the filters are able to detect even more sophisticated objects like full dogs, cats, lizards, and birds.\n",
    "\n",
    "<img src=\"./resources/layers.png\"  style=\"height: 400px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution in more detail\n",
    "\n",
    "Say we have an image that has 7x7 pixel data with the three basic colors: Red, Green and Blue. This means the data has a 7x7x3 volume. If we are to detect the certain features with 4 filters, the convolution computation occurs for each filter. Please pay attention to the volume of the outcome. See how the height, the width and the depth changed. If we use a bigger size of filters, the __height__ and the __width__ will be bigger. And the number of filters will determine the __depth__ of the outcome.\n",
    "\n",
    "<img src=\"./resources/filter3.png\"  style=\"height: 300px\"/>\n",
    "\n",
    "\n",
    "### Convolution with padding and stride\n",
    "\n",
    "You may already have noticed that the pixels of the image aren’t processed with the same number. The pixels at the corner are less counted than those in the middle. This means that the pixels don’t get the same amount of weights. Additionally, if we just keep applying the convolution, we might lose the data too fast. Padding is the trick we can use here to fix this problem. As its name suggests, padding means giving additional pixels at the boundary of the data.\n",
    "\n",
    "<img src=\"./resources/padding.gif\"  style=\"height: 250px\"/>\n",
    "\n",
    "The __first__ example on the picture above is showing what we have done so far. The input image has 4x4 pixels and the filter has 3x3. There is no padding, which is called __valid__. The result becomes 2x2 pixels data (4 – 3 + 1 = 2). We can see that the output data is downsized.\n",
    "\n",
    "Let's see the __third__ example this time. There is one layer padding with the blank pixels. The input image has 5x5 pixels and the filter has 3x3. So the result gets 5x5 pixels (5 + (1 x 2) – 3 + 1 = 5), which is the same size as the input image. We call this __same__. \n",
    "\n",
    "We can even make the outcome bigger than the input data, but the two cases above are used the most.\n",
    "\n",
    "By the way, does a filter always have to move one pixel at a time? Of course not. We can also make it move two steps or three steps at a time both in the horizontal and vertical ways. This is called __stride__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Pooling\n",
    "\n",
    "Let's move on to the second operation. The video below (from 0:47 till 7:22) will explain the operation of *Max Pooling* - the most used pooling technique - although there are other pooling strategies, for example Average Pooling.\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/ZjM_XQa5s6s?start=47&end=442\"><img src=\"resources/video3.png\" width=\"400\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What have we learned?\n",
    "\n",
    "- Max pooling is a type of operation that is typically added to CNNs __following individual convolutional layers__.\n",
    "\n",
    "- When added to a model, max pooling reduces the dimensionality of images by reducing the number of pixels in the output from the previous convolutional layer.\n",
    "\n",
    "- Since max pooling is reducing the resolution of the given output of a convolutional layer, the network will be looking at larger areas of the image at a time. Going forward this reduces the __amount of parameters__ in the network and consequently __reduces__ computational load.\n",
    "\n",
    "<img src=\"./resources/pooling.png\"  style=\"height: 150px\"/>\n",
    "\n",
    "- The purpose of pooling is reducing the size of the data. Sliding a window, we only take the maximum value inside the box on the left case. This is __max pooling__. We can also take the average values like the picture on the right. This is __average pooling__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Flattening & Full connection\n",
    "\n",
    "Flattening and fully-connected layers are what we have at the last stage of CNN, which means you're almost there!  Great. By the way, you didn’t forget why we are doing these, right? What are we doing? Image processing. What for? Classifying images. We are making a classification model, which means these processed data should be good input to the model. It needs to be in the form of a 1-dimensional linear vector. Rectangular or cubic shapes can’t be direct inputs. And this is why we need flattening and fully-connected layers.\n",
    "\n",
    "<img src=\"./resources/flatten.png\"  style=\"height: 300px\"/>\n",
    "\n",
    "Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer. In other words, we put all the pixel data in one line and make connections with the final layer.\n",
    "\n",
    "### In one shot\n",
    "\n",
    "Now let’s see what we’ve walked through in one shot.\n",
    "\n",
    "<img src=\"./resources/cnn.jpeg\"  style=\"height: 270px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this notebook, the last video (from 0:00 till 1:28) shows a small recap of all we've learned and is a good introduction to the following Notebook where we are going to build a CNN ourselves to classify the images of cats and dogs.\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/yOAPyrKqrno\"><img src=\"resources/video4.png\" width=\"400\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
