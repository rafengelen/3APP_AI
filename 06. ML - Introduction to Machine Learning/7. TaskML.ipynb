{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## General Guidelines - Tasks: \n",
    "### **ipynb - pdf - Streamlit app**\n",
    "\n",
    "During the practical part of this course, each student has to complete three individual tasks, one for each of the three domains of AI that we'll cover.\n",
    "For each of those tasks, a notebook with the task description, and some general steps of what we expect to be covered in the solution, will be provided. \n",
    "We also expect you to **use Generative AI tools** to assist you in creating a solution. So, definetely have a look at our Generative AI Policy description as well.\n",
    "\n",
    "Each of the tasks, deals with a problem that first has to be solved via Python code, in a **Jupyter notebook (.ipynb) format**, so you can switch between code and comments (in Markdown). Also make sure, that you can **export the .ipynb into a pdf**, including the output of the code cells, since this will also be a **requirement on the practical exam**. You can even extend your notebook, to create a full blown report (see below).\n",
    "\n",
    "Next, this code has to be transformed into a **Streamlit application** (a very user friendly Python based web application framework). Streamlit is not part of the course material itself, and you're expected to master the basic principles yourself. It's really straightforward to use, especially if you use Bing AI or other GenAI tools. It will lift your simple tasks from code 'living in a notebook', to a nice visual web application, in a matter of minutes (after some practise). Another advantage of using Streamlit, is that you can even include the app in your online portfolio, if you want to.\n",
    "\n",
    "Finally, each tasks should have a **report in pdf**, where you explain your application, the different steps you took to get to the result, the reasoning/intention behind those steps, extra visualisations to make the solution more explainable, problems/roadblocks/speedbumps you encountered and how you conquered them, etc. And, **including a section on the GenAI tools** you employed (see GenAI Policy), and **the prompts** you used to generate your desired result. This report can be part of the exported Jupyter notebook (preferred), or can be a completely stand-alone new report.\n",
    "\n",
    "\n",
    "### General deliverables for each of the tasks:\n",
    "- a pdf version of your notebook, including the cell outputs (preferrably also including the reporting part)\n",
    "- a streamlit app. Preferrably a 'private' URL where we can test your application live. If your app isn't live, include screenshots in your report as well.\n",
    "- a pdf report, if you didn't include it in the pdf of your notebook\n",
    "\n",
    "\n",
    "### General Grading Guidelines\n",
    "\n",
    "Each task will have their own specific grading, but as a general guideline:\n",
    "\n",
    "The grading will be on a scale of 0 (insufficient completion of task, including not completing one or more subtasks, and/or insufficient reporting style) to 0.5 (completed every element of the task, but poor reporting style), to 1 (task completed, impressive solution, good reporting style)\n",
    "\n",
    "### Streamlit\n",
    "\n",
    "Streamlit is an easy to use Python webframework, and you can find many online tutorials to help you transform your code into a live Streamlit webapp. Remember: you are encouraged to use GenAI tools to get the job done.\n",
    "\n",
    "A couple of YouTube channels, explaining the possibilies of Streamlit very well:\n",
    "\n",
    "- Misra Turp: https://www.youtube.com/watch?v=-IM3531b1XU&list=PLM8lYG2MzHmRpyrk9_j9FW0HiMwD9jSl5&ab_channel=M%C4%B1sraTurp\n",
    "- Data Professor: https://www.youtube.com/watch?v=ZZ4B0QUHuNc&list=PLtqF5YXg7GLmCvTswG32NqQypOuYkPRUE&ab_channel=DataProfessor\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task ML. Benchmarking two ML algorithms\n",
    "\n",
    "In class, we've covered a couple of different data-driven ML algorithms for classification (i.e. Decision Tree Classifier, Random Forest Classifier) and regression (i.e. Linear Regression), and a couple of different rectangular/structured datasets (weather dataset, wine quality dataset, tennis dataset, iris dataset, breast cancer dataset).\n",
    "\n",
    "These are just a couple of different ML techniques out there. Since ScikitLearn is the Python GoTo-library for ML, it has bundled the most common techniques in a simple hierarchy (the diagram depicts the most used algorithms, but there are a lot more out there).\n",
    "\n",
    "<img src=\"./resources/Classifiers.png\"  style=\"height: 250px\"/>\n",
    "\n",
    "<img src=\"./resources/Regressors.png\"  style=\"height: 250px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other datasets, we could look at the standard datasets that are packaged in the library itself [Scikit Toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html), or at more challenging/competition worthy datasets from Kaggle.com. \n",
    "\n",
    "But for this challenge, we will take a look at the repository from UCI [University of California](https://archive.ics.uci.edu/ml/index.php), where we can find and download very popular data sets. If you go to the ['View All datasets' link](https://archive.ics.uci.edu/ml/datasets.php), you get an overview of all available datasets, together with a small summary. \n",
    "On the left, you can filter on regression or classification problems, multivariate data types, and so on.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your challenge: \n",
    "\n",
    "##### 1. Find a dataset from the UCI site that you like + perform simple EDA\n",
    "- Give a small explanation why you've chosen that particular dataset, and why you want to perfom classification and/or regression on it.\n",
    "   - Requirements: minimal 5 different attributes, and minimal 100 instances. You can choose between a classification task, or a regression task. You can't pick a dataset from the ones we've already covered in class\n",
    "- perform a **small EDA** (Exploratory Data Analysis - see Data Science course)\n",
    "   - with the EDA you can prove that the data set complies with the minimal requirements, check basic statistics, check for missing data (and consequently deal with them in a suitable manner), check for unbalanced features,...\n",
    "\n",
    "##### 2. Split the data into a training and test set\n",
    "- Make sure all algorithms use the same train and test set, otherwise it isn't a fair benchmark\n",
    "   \n",
    "##### 3. Use a technique we've covered in class to do classification/regression on this dataset (=baseline)\n",
    "- The baseline is needed as a comparison metric for other algorithms.\n",
    "\n",
    "##### 4. Choose 2 other ML techniques from the ScikitLearn library\n",
    "- The algorithms should be different from the ones we've covered in class. Try to explain in your own words how those algorithms work, what they do. We know that some algorithms are pretty hard to understand, but make an effort. Use GenAI tools, if need be. This is an ideal use case for you to demonstrate your prompt engineering skills! Try to use metaphors, or visualizations, to explain hard to grasp concepts.  \n",
    "- Try to explain each algorithm in a couple of paragraphs. We don't want entire pages of explanation. Just the basic core working principles of the algorithm. And make sure you understand it as well. Maybe, add some prompts to ask the GenAI tools to ask you some small quiz questions on the algorithm, it just explained to you. This way, you can deepen your own understanding, or ask interesting follow-up questions if you get something wrong.\n",
    "\n",
    "   **Remember:** add a paragraph in your report on the use of GenAI tools, and the prompts you used. Otherwise, it might be considered plagerism\n",
    "\n",
    "##### 5. Model the dataset with the selected 2 techniques as well, and compare them to the baseline. \n",
    "- And finally, train your models, and run the test set on them. \n",
    "- **Explain the results, and compare the different models on performance.** \n",
    "\n",
    "Hint: for regression tasks, performance is usually measured via RMSE (Root Mean Square Error). You can go for more elaborate performance measures (R2 for example), but this might be overkill for this assignment. For classification, you can use accuracy (if you want a single number), or the confusion matrix if you want a more 'overview-comparison'. Again, overkill for this assignment, but if you're interested: research ROC / AUC, F1 score,etc. if you want more elaborate evaluations to do comparisons...\n",
    "\n",
    "Hint: only compare performance on the **test set. Never on the training set**!\n",
    "   \n",
    "##### 6. Combine everything into one notebook, and export to pdf\n",
    "- As for all assignments, make sure you can create a nice pdf report of everything you did, with a small intro, and at the end a conclusion. Don't forget to include the GenAI segment!\n",
    "\n",
    "##### 7. Streamlit app\n",
    "- Create a streamlit app from your code. This way you can visualize the EDA,  you can switch between the different machine learning algorithms, you can compare them, etc. \n",
    "- If those algorithms have (hyper)parameters you can adjust / tweak (for instance the number of trees in a random forest), add some controls in the app so it's easy for the user to select a different option, and compare the result to the other algorithms. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be submitted \n",
    "\n",
    "\n",
    "- a pdf version of your notebook, including the cell outputs and comments (preferrably **also including the reporting part**)\n",
    "- a pdf report (if you didn't include it in the pdf of your notebook)\n",
    "- a streamlit app \n",
    "    - as an URL where we can test your application live (we don't need the streamlit code in this case) - Checkout the Streamlit Community Cloud to deploy your app via Github\n",
    "    - if your app isn't live, include screenshots in your report as well, and include the code of the app in a seperate section of your pdf.\n",
    "\n",
    "We know that solutions can be found on the internet, or via GenAI tools. You may use those to get started, but don't copy them blindly! You are going to get the most satisfaction out of this assignment if you try to code it - at least partially - yourself. And don't forget a **section in your report about the GenAI usage**.\n",
    "\n",
    "## Grading\n",
    "\n",
    "During the grading we will take into account:\n",
    "\n",
    "- is your code neatly structured?\n",
    "- do you have enough comments / explanations? Do they reflect that you have a solid understanding of the code?\n",
    "- is the report clear, professional, and does it give a good overall impression? No _bric a brac_\n",
    "- how impressive is the live app, or the screenshots when the app isn't live? Does it do what we asked it to do?\n",
    "- how's the usage of GenAI in this assignment?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ML_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3762fa38335283772957b8ad4850e1d344741e862c3aa7ec1c26d17780db6975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
