{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Gender Identifier - Exercise\n",
    "\n",
    "Gender identification is another interesting NLP problem. \n",
    "\n",
    "In this Notebook, we will use a **heuristic** to construct a feature vector and use it to train a classifier. The heuristic that we will use here is the last N letters of a given name. For example, if the name ends with \"ly\", it's most likely a female name, such as \"Holly\", \"Kelly\" or \"Emely\". On the other hand, if the name ends with \"rk\", it's likely a male name such as \"Clark\", \"Mark\" or \"Dirk\". Since we are not sure of the exact number of letters to use, we will play around with this parameter and find out what the best answer is.\n",
    "\n",
    "We will use the same approach as for the sentiment analyzer and build and train a Naive Bayes Classifier.\n",
    "\n",
    "BTW: combining letters or words into patterns is another popular way to tokenize your text. It's called a **'n-gram'**, where n equals the amount of items (chars or words) we combine into a token. \n",
    "\n",
    "<img src=\"./resources/ngram-words.png\"  style=\"height: 250px\"/>\n",
    "<img src=\"./resources/ngrams_char.jpg\"  style=\"height: 250px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the names\n",
    "\n",
    "First import the NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resources you will find two text documents `male.txt` and `female.txt` with the most common names in the Netherlands and Belgium of the last two years. Read the names in these documents and create two variables *male_names* (an array with all the male names) and *female_names* (an array with all the female names). You should get (for the *male_names*):\n",
    "\n",
    "```\n",
    "['Aad', 'Aalbert', 'Aaldert', 'Aaldrik', 'Aalt', 'Aarnoud', ... ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(male_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shuffle the names\n",
    "\n",
    "Now create a new array *data* (using the previous two arrays) with all the male and female names (randomly shuffled). Indicate if the name is male or female. You should get something like this:\n",
    "\n",
    "```\n",
    "[('Jitske', 'female'), ('Etienne', 'male'), ('Danischa', 'female'), ... ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the featureset\n",
    "\n",
    "In the example of the sentiment analyzer, we used every top 3,000 word as an input feature for our classifier. Whether the word existed in the document (true or false) was the value of the feature. As output feature or label we used pos or neg. Therefore the featureset used to train the classifier was something like this (we only used the top 3 words and the first 5 documents).\n",
    "\n",
    "```\n",
    "[({'plot': True, 'bothered': False, 'annual': False}, 'pos'), ({'plot': False, 'bothered': False, 'annual': False}, 'pos'), ({'plot': False, 'bothered': False, 'annual': False}, 'pos'), ({'plot': True, 'bothered': True, 'annual': False}, 'pos'), ({'plot': True, 'bothered': True, 'annual': False}, 'neg')]\n",
    "```\n",
    "\n",
    "In this example there is only one input feature, namely the last N letters from the name in __lowercase__. The output feature is male of female. Therefore the array we have to create to train our classifier must have this format:\n",
    "\n",
    "```\n",
    "[({'letters': 'rissa'}, 'female'), ({'letters': 'rigje'}, 'female'), ({'letters': 'amos'}, 'male'), ({'letters': 'kbule'}, 'female'), ({'letters': 'nady'}, 'female'), ({'letters': 'ienna'}, 'female'), ({'letters': 'lÃ©rie'}, 'female'), ({'letters': 'berta'}, 'female'), ({'letters': 'rigje'}, 'female'), ({'letters': 'tiny'}, 'female')]\n",
    "```\n",
    "\n",
    "Create a function `create_featureset` with two parameters: the first parameter is N (the number of letters), the second parameter is data (all the male and female names shuffled). The return value of the function is the featureset from above (in the case of N=5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_featureset(5,data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and classify\n",
    "\n",
    "Create an array with the input names to classify. Write a loop (1 to 5) to classify the names using the last 1, 2, ... 5 letters. Print the accuracy of the classifier and the predicted gender of the name. The output should be:\n",
    "\n",
    "```\n",
    "Number of end letters: 1\n",
    "Accuracy = 77.34%\n",
    "Yvonne - {'letters': 'e'} ==> female\n",
    "Johan - {'letters': 'n'} ==> male\n",
    "Yvette - {'letters': 'e'} ==> female\n",
    "Patrick - {'letters': 'k'} ==> male\n",
    "Heidi - {'letters': 'i'} ==> female\n",
    "Jos - {'letters': 's'} ==> male\n",
    "Carine - {'letters': 'e'} ==> female\n",
    "\n",
    "Number of end letters: 2\n",
    "Accuracy = 78.73%\n",
    "Yvonne - {'letters': 'ne'} ==> female\n",
    "Johan - {'letters': 'an'} ==> male\n",
    "Yvette - {'letters': 'te'} ==> female\n",
    "Patrick - {'letters': 'ck'} ==> male\n",
    "...\n",
    "```\n",
    "\n",
    "Normally the accuracy should peak at two letters and start decreasing after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = ['Yvonne', 'Johan', 'Yvette', 'Patrick', 'Heidi', 'Jos', 'Carine']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
