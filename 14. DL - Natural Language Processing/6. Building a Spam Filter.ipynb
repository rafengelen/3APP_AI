{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter - Exercise\n",
    "\n",
    "Spam filtering is a classic example of a binary classification task. In this Notebook you’ll learn how to implement your own one.\n",
    "\n",
    "The task is to distinguish between two types of emails, \"spam\" and \"non-spam\" often called \"ham\". The machine learning classifier will detect that an email is spam if it is characterised by certain features (mainly the existence of words like \"Viagra\" or \"lottery\" or phrases like \"You’ve won a $100,000,000! Click here!\" and \"Join now!\").\n",
    "\n",
    "Once again, we will use the same approach as for the sentiment analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import\n",
    "\n",
    "As always we're going to use the Naive Bayes classifier. This is a pretty popular classifier used in text classification, sentiment analysis, spam filtering, ... Import the necessary NLTK packages for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy as nltk_accuracy\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the data\n",
    "\n",
    "In the resources folder you will find two subfolders spam and ham which contains 1,500 legitimate (ham) emails and 4,500 spam emails.\n",
    "\n",
    "To start with, create two variables `spam_list` and `ham_list` and try to write a program that fills these variables with the names of the spam and ham emails. Print the names of the spam documents and the total number of spam and ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to print the content of the first spam file. You should get (tip: use the word tokenizer):\n",
    "\n",
    "```\n",
    "['subject', ':', 'adv', ':', 'space', 'saving', 'computer', 'to', 'replace', 'that', 'big', 'box', 'on', 'or', 'under', 'your', 'desk', '!', '!', 'revolutionary', '!', '!', '!', 'full', 'featured', '!', '!', '!', 'space', 'saving', 'computer', 'in', 'a', 'keyboard', 'eliminate', 'that', 'big', 'box', 'computer', 'forever', '!', 'great', 'forhome', '.', '.', '.', '.', 'office', '.', '.', '.', 'or', 'students', '.', '.', '.', 'any', 'place', 'where', 'desk', 'space', 'is', 'at', 'a', 'premium', '!', 'the', 'computer', 'in', ... ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a list of documents\n",
    "\n",
    "Create a list of documents in the following format:\n",
    "\n",
    "```\n",
    "[(['subject', 'space', 'saving', 'computer', 'replace', ...], 'spam'), \n",
    " (['subject', 'miningnews', 'net', 'newsletter', 'thursday', ...], 'spam'), \n",
    " (['subject', 'say', 'goodbye', 'doctor', 'visits', ...], 'spam'), \n",
    " (['subject', 'annoy', 'you', 'eternal', 'benson', ...], 'spam'),\n",
    " (['subject', 'scott', 'leaving', 'intel', 'today', ...], 'ham'), ...]\n",
    "```\n",
    "\n",
    "Use random to shuffle your documents. This is because we're going to train and test. If we left them in order, we'd train on all of the spam emails and then test only against ham emails. We don't want that, so we shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect the top 3,000 words\n",
    "\n",
    "Make a new variable `top_words` which contains the top 3,000 most common words. Don't forget to remove the stopwords and the punctuation. Also remove the one-letter words and numbers. Printing the first 20 top 3,000 words frequency should give:\n",
    "\n",
    "```\n",
    "[('subject', 6873), ('com', 3258), ('``', 2617), ('http', 2523), ('data', 2363), ('please', 2293), ('database', 2163), ('company', 2120), ('dbcaps', 2010), ('date', 1827), ('time', 1737), ('email', 1733), ('hourahead', 1729), ('get', 1724), ('information', 1715), ('hour', 1658), ('start', 1627), ('us', 1586), ('www', 1520), ('may', 1497)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the featureset\n",
    "\n",
    "Use every top 3,000 word as an input feature for your classifier. Whether the word exists in the mail (true or false) is the value of the feature. Use spam or ham as output feature or label. Therefore the featureset used to train the classifier should look something like this.\n",
    "\n",
    "```\n",
    "[({'subject': True, 'annuity': False, 'deal': False, ...}, 'spam'), ({'subject': False, 'annuity': False, 'deal': False, ...}, 'ham'), ... ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featuresets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the classifier \n",
    "\n",
    "Now it is time to separate our data into training and testing sets, and press go! The algorithm that we're going to use is the Naive Bayes classifier. Train the classifier with 90% of the data.\n",
    "\n",
    "After training print the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print what the most valuable words (top 15) are when it comes to spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the classifier\n",
    "\n",
    "In the test folder you can find 10 mails (spam and ham). Use these mails as input for your classifier and check if you can classify them correctly as spam or ham. You should get:\n",
    "\n",
    "```\n",
    "File: 0010.2003-12-18.GP.spam.txt => spam Probability: 0.75\n",
    "Content:\n",
    "Subject: re : hot topics : growing young\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "File: 0166.2001-04-18.williams.ham.txt => ham Probability: 1.0\n",
    "Content:\n",
    " Subject: new hire dinner rsvps\n",
    "don ' t forget to let me know if you are interested in attending the new hire dinner at 6 pm on thursday , april 26 th ! it will be held at oritalia at the westin hotel . please indicate your meal selection ( meat - - beef , or veggie - - pasta ) . i will need to submit final entree numbers thursday morning ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
