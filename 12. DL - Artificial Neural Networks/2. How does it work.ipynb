{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does a Neural Network actually work?\n",
    "\n",
    "We already know that a neural network is a type of machine learning model, which is inspired by how the human brain works. It will create a network of neurons that are connected to eachother (mostly in layers), and that, via an algorithm that is given data over and over again, allows the computer to learn. So, a neural network is an iterative learner, that will learn to make certain connections, neural pathways, more important than others. In the beginning it will make many (and big) mistakes, but over time the algorithm will make sure that the network gets better and better. This is called training a neural network, or fitting it to the data. \n",
    "\n",
    "You can compare it to a baby, or child, learning to identify a cat. We keep giving examples of a cat via images, drawings, or pointing them out in real life, and we ask the child: is this a cat?, is this a cat?, is this a cat? Note: we don't explicitely tell the child what features to look for, we just give it examples. The child has to make the abstraction of what a cat is, by herself. So make a generalization of what a cat is. In the beginning the child will make many mistakes, but by giving feedback (correct or not), over time, the child will learn. The neural pathways in the brain keep getting stronger whenever a cat is correctly identified.\n",
    "\n",
    "An artificial neural network will work very similar. It will make an abstraction of the concept 'cat' by giving certain neural connections more weight, than others. The abstraction, or generalization, of a concept is called the 'model'. Once we have a model, or mental image what it is that makes it a cat, we can query it with previously unseen data/image: is this a cat? If the model has done a good job generalizing the concept of a cat, then it will be able to answer correctly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Key principles\n",
    "\n",
    "In the first video (from 0:00 till 13:26) the key principles of a neural network will be explained using the classic example of putting together a neural network that can learn to recognize handwritten digits. There will be a little bit of math in the video, but don't be scared of it. It's not that complex, and in real life you don't really need to know the math. It just helps you to understand the principes behind it a little better. It's not a magical black box. It's just math...\n",
    "\n",
    "After we got the basic princples straight, the second video will explain how a neural network is trained.\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/aircAruvnKk?start=4&end=806\"><img src=\"resources/video1.png\" width=\"400\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summary \n",
    "\n",
    "### Neuron\n",
    "\n",
    "A neuron is a *thing* that holds a number between 0 and 1. The value of a neuron is also called its activation. \n",
    "Actually, it's the result of an activation function, a *squishing* function, like the *sigmoid* (it will squeeze the output range from whatever to the range of [0,1] - the range we want to use with our neurons). The input to this 'squishing'-function is the weighted sum of the previous layer it's activations, offset by a bias.\n",
    "\n",
    "Don't worry about the math: the concepts behind deep learning are pretty complex, but using them in code is made really easy by the use of our deep learning platforms, like Keras. \n",
    "\n",
    "<img src=\"./resources/ANN1.png\"  style=\"height: 150px\"/>\n",
    "\n",
    "### The layered structure of our network\n",
    "\n",
    "- **Input layer**: the first layer of this example network, consist out of 28x28=784 neurons. The value of each neuron is the grey scale of the pixel (ex 0.58). This number of neurons is determined by your input-data (the X). If you have 5x5 pixels input images, you would have 25 input neurons. If you had 10x10 images, you would have 100 input neurons. \n",
    "\n",
    "Note: you can imagine that if we use typical resolutions of 640x320 images or bigger, we need a really big input layer (204.800). That's why, in our next lesson, we will fix this issue with a CNN network. But for now, let's stay with the basics of small inputs.\n",
    "\n",
    "- **Hidden layers**: \n",
    "    - The first hidden layer might try to recognize the various little edges. So it tries to combine different parts of your input-data, in an effort to find basic patterns, like edges. The amount of neurons we use in the first hidden layer (called the width of the layer), isn't set in stone. There is no exact way to determine how many there should be. It's more trial and error, and experimenting what works, and what doesn't.\n",
    "    - The second hidden layer might try to combine the small patterns from the previous layer, into bigger patterns, to try to identify bigger patters the digits are made up from. Again, the amount of neurons in this layer is determined by trial and error, or experience, not a fixed rule.\n",
    "    \n",
    "Note: there might be more hidden layers in other networks, again no fixed rule on how many. The amount of hidden layers will determine how **deep** our network will be (aka **deep learning**), how flexible it will be (more degrees of freedom to map whatever input you throw at it). \n",
    "\n",
    "- **Output layer**: the last layer consist out of 10 neurons. This amount of output neurons is determined by your output-data, the labels (the y). If you only had to determine: cat or no cat, then 1 output neuron is enough. The activation-value (or output value) of each neuron corresponds to how much the system thinks that a given image corresponds to the given digit.  \n",
    "\n",
    "<img src=\"./resources/ANN2.png\"  style=\"height: 400px\"/>\n",
    "\n",
    "### The parameters of the network\n",
    "\n",
    "- Assign a weight to every edge, which connects a neuron with the neurons of the previous layer.\n",
    "- Take all the activations of the previous layer, and compute the weighted sum according to these weights.\n",
    "- Add a bias, that tells you how high the weighted sum needs to be, before the neuron is activated (the neuron 'fires').\n",
    "- Activations (or output value of a neuron) should be a value between 0 and 1, so se a function (sigmoid) to convert (squish) the weighted sum to a value between 0 and 1.\n",
    "\n",
    "<img src=\"./resources/ANN3.png\"  style=\"height: 350px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How do Neural Networks learn?\n",
    "\n",
    "Learning is the adaptation of the network to better handle a task - in our case recognizing digits - by considering sample observations. Learning involves adjusting the weights and biases of the network to improve the accuracy of the result. This is done by minimizing the cost, or error, or loss, the network makes. The cost can be calculated when we compare the output of our model, the prediction, and the actual label. The goal is to update the weights, each time we give it data, in such a way that the mistake our network makes, is a little less each time. \n",
    "\n",
    "Think of those parameters, those weights, as knobs on a DJ soundboard. Those knobs have a certain startposition, and we run a soundtrack (input data) through the soundboard, so it produces a sound (output). The sound produced isn't that great. It's errored. We need to turn each of these knobs into a better position (update our weights), so if we play the same soundtrack again, the sound produced is a little better. To measure if we did better, we need some kind of error-(or cost-, or loss) function. The hope is, that if we do this for multiple soundtracks, that we end up with a perfectly tuned soundboard, that plays awesome music. \n",
    "\n",
    "This will be explainded in detail in the video below (from 0:29 till 5:21).\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=29&end=321\"><img src=\"resources/video2.png\" width=\"400\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "### 4.1 Learning\n",
    "\n",
    "In total the network has 13,002 weights and biases that we can adjust. These values determine what exactly the network does. Training the network means finding the right weights and biases.\n",
    "\n",
    "<img src=\"./resources/ANN4.png\"  style=\"height: 250px\"/>\n",
    "\n",
    "### 4.2 Training the network\n",
    "\n",
    "- First all the weights and biases are initialized randomly. The network is going to perform horribly.\n",
    "\n",
    "- The cost function adds up the squares of the differences between the values of the predicted activations and the values we want them to have. This sum is small when the network classifies the image correctly.\n",
    "- The average cost over all of the training examples is a measurement of how good the network is.\n",
    "- Training/learning involves adjusting the weights and biases of the network to improve the accuracy of the result. This is done by minimizing the average cost.\n",
    "\n",
    "<img src=\"./resources/ANN5.png\"  style=\"height: 350px\"/>\n",
    "\n",
    "### 4.3 Testing the network\n",
    "\n",
    "- After we trained the network, we show it more labeled data that it has never seen before. We see how accurate it classifies these new images.\n",
    "\n",
    "<img src=\"./resources/ANN6.png\"  style=\"height: 350px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Math\n",
    "\n",
    "By now, we know the very basics of the structure of a Neural Network and how it can be trained. A complete in depth explanation will require a lot of math. Therefore we will not dig any deeper, but we will give you a brief explanation below, but it falls **outside of the scope of this introduction course** (but for those who want to persue AI definitely worth while digging a little deeper). But, do remember the recap definitions at the end of this notebook, because we'll encounter them again in code.\n",
    "\n",
    "The **error (or cost, or loss) function**: we'll also use this function to guide us on how we should turn each knob: up or down (make our weight bigger or smaller). Since this error-function, can be expressed in terms of the weights (the knobs on the DJ board), we can try to find the minimum of this loss function, the optimal position of the weights that produce the least amount of error. \n",
    "\n",
    "The problem is that there are many, many, many weights, and they are all connected to eachother. Changing one, influences the behavior of all other connected weights. So this creates a really difficult function, where we can't easily find the very best settings of the weights to produce the least possible error. \n",
    "\n",
    "But, here mathematics come in handy! \n",
    "\n",
    "We can try to calculate a gradient (like a derivative) of that function, in respect to a certain weight. Hopefully, you'll remember from math/calculus, that if you calculate a derivative or gradient of a function, it will give you a kind of slope, a direction of change (in Dutch: *richtingscoefficient*), in our case the direction of the error going up. So, calculating this gradient for a certain weight, a knob on the DJ board, will give us the direction on how to update that weight to make the error bigger. Of course, we want a lesser error, so we adjust it in the opposite way, so the error goes down. This technique is called **gradient descent**, using the gradient of the error-function to tweak the weights in that direction, where we make less of an error. And we do this over, and over again, since we can only take rather small steps when we adjust the weights (see learning rate below).\n",
    "\n",
    "And, because the function we use to calculate this update is so complex due to the interconnection between neurons, we start by running our data through our network in a forward pass, so we can calculate the error in the last layer, and know the direction on how to update the weights in that layer, because it directly influences the output result. Ofcourse, we can't completely calculate it yet, since we don't know how to update the previous layers yet. That's why we use this function recusively, and work our way back to the beginning. This is called **backpropagation**. \n",
    "\n",
    "And as a final touch: since we only know the direction on how to update the weights to make the network perform better: we still don't know by how much we should tweak it. That's where the **learning rate** comes into play. Determining a good learning rate, is one of the hardest things to do while training a neural network. Too big, and you will overshoot the optimal settings, too small and it will take a very long time to reach the optimal settings... And, to make matters worse: the loss function usually has a lot of local minimums where we can get stuck in suboptimal settings. That's why we often use **optimizers**, like *adaptive momentum (adam)*.\n",
    "\n",
    "<img src=\"./resources/gradient_descent.png\"  style=\"height: 350px\"/>\n",
    "\n",
    "This will be explainded in detail in the remainder of our previous video (from 5:21 till 8:33).\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=321&end=513\"><img src=\"resources/video2.png\" width=\"400\"></a>\n",
    "\n",
    "## 6. Recap\n",
    "\n",
    "Remember these definitions:\n",
    "\n",
    "- __Gradient descent__ is a iterative optimization algorithm for finding a set of weights and biases which make the cost as small as possible.\n",
    "- __Backpropagation__ is a recursive and efficient method for calculating the weight updates to improve the network until it is able to perform the task for which it is being trained.\n",
    "- __Learning rate__ is a parameter that controls how much the model changes in response to the error, each time the model weights are updated\n",
    "- __Optimizers__ are used to help the gradient descent algorithm to find a good set of weights and biases. Adam is generally considered a good optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
