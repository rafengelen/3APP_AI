{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Cab\n",
    "\n",
    "Let's design a simulation of a self-driving cab. The major goal is to demonstrate, in a simplified environment, how you can use RL techniques to develop an efficient and safe approach for tackling this problem.\n",
    "\n",
    "The Smartcab's job is to pick up the passenger at one location and drop him off in another. Here are a few things that we'd love our Smartcab to take care of:\n",
    "\n",
    "- Drop off the passenger at the right location.\n",
    "- Save passenger's time by taking minimum time possible to drop off\n",
    "- Take care of the passenger's safety and the traffic rules\n",
    "\n",
    "There are different aspects that need to be considered here while modeling an RL solution to this problem: rewards, states, and actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rewards\n",
    "\n",
    "Since the agent (the imaginary driver) is reward-motivated and is going to learn how to control the cab by trial experiences in the environment, we need to decide the rewards and/or penalties. Here a few points to consider:\n",
    "\n",
    "- The agent should receive a high positive reward for a successful dropoff because this behavior is highly desired.\n",
    "- The agent should be penalized if it tries to drop off a passenger in wrong locations.\n",
    "- The agent should get a slight negative reward for not making it to the destination after every time-step. *Slight* negative because we would prefer our agent to arrive late instead of making wrong moves trying to reach the destination as fast as possible (safety first)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Space\n",
    "\n",
    "In Reinforcement Learning, the agent encounters a state, and then takes an action according to the state it's in. The State Space is the set of all possible situations our taxi could inhabit. The state should contain all useful information the agent needs to make the right action.\n",
    "\n",
    "Let's say we have a training area for our Smartcab where we are teaching it to transport people in a parking lot to four different locations (R, G, Y, B):\n",
    "\n",
    "<img src=\"./resources/taxi.png\" style=\"height: 350px\"/>\n",
    "\n",
    "Our state then consists of:\n",
    "\n",
    "- __the current position of our smartcab__: We can break up the parking lot into a __5x5__ grid, which gives us 25 possible taxi locations. Notice the current location state of our taxi is coordinate (3, 1).\n",
    "\n",
    "- __the current location of our passenger__: There are four (4) locations where we can pick up a passenger: R, G, Y, B or [(0,0), (0,4), (4,0), (4,3)] in (row, col) coordinates. Our illustrated passenger is in location Y. Since the passenger can also be inside the taxi, there are __5__ possible locations for our passenger.\n",
    "\n",
    "- __the destination location__: There are four locations where we can drop off a passenger: R, G, Y, B, so __4__ possible locations.\n",
    "\n",
    "So, our taxi environment has 5×5 × 5 × 4 = 500 total possible states (taxi location x passenger location x dropoff location)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Action Space\n",
    "\n",
    "The agent encounters one of the 500 states and it takes an action. The action in our case can be to move in a direction or decide to pickup/dropoff a passenger.\n",
    "\n",
    "In other words, we have six possible actions:\n",
    "\n",
    "1. south\n",
    "2. north\n",
    "3. east\n",
    "4. west\n",
    "5. pickup\n",
    "6. dropoff\n",
    "\n",
    "This is the action space: the set of all the actions that our agent can take in a given state.\n",
    "\n",
    "You'll notice in the illustration above, that the taxi cannot perform certain actions in certain states due to walls. We will simply provide a -1 penalty for every wall hit and the taxi stays at the current location. This will just rack up penalties causing the taxi to consider going around the wall.\n",
    "\n",
    "Let's implement and solve this problem in Python. Fortunately, OpenAI Gym has this exact environment already built for us."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ML_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3762fa38335283772957b8ad4850e1d344741e862c3aa7ec1c26d17780db6975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
